{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Let's write an example of concurrent write and read to a Azure queue as an example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. We create a queue "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating queue: queue-tdu\n"
     ]
    }
   ],
   "source": [
    "from azure.storage.queue import (\n",
    "        QueueClient,\n",
    "        BinaryBase64EncodePolicy,\n",
    "        BinaryBase64DecodePolicy\n",
    ")\n",
    "\n",
    "import os, uuid\n",
    "\n",
    "# Retrieve the connection string from an environment\n",
    "# variable named AZURE_STORAGE_CONNECTION_STRING\n",
    "connect_str = os.getenv(\"AZURE_STORAGE_CONNECTION_STRING\")\n",
    "\n",
    "# Create a unique name for the queue\n",
    "queue_name = \"queue-\" + \"tdu\"\n",
    "\n",
    "# Instantiate a QueueClient object which will\n",
    "# be used to create and manipulate the queue\n",
    "print(\"Creating queue: \" + queue_name)\n",
    "queue_client = QueueClient.from_connection_string(connect_str, queue_name)\n",
    "\n",
    "# Create the queue\n",
    "# queue_client.create_queue()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Create a thread pool randomly publish message to the queue \n",
    "This can be ran in a different process with multiple thread to publish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import threading, itertools\n",
    "\n",
    "import random\n",
    "def uniqueid():\n",
    "    while True:\n",
    "        seed = str(uuid.uuid4())\n",
    "        yield seed\n",
    "        \n",
    "def task(uuid):\n",
    "    message = \" \" + uuid\n",
    "    queue_client.send_message(message)\n",
    "\n",
    "unique_sequence = uniqueid()\n",
    "ids = list(itertools.islice(unique_sequence, 3000))\n",
    "\n",
    "with ThreadPoolExecutor(max_workers=50) as pool:\n",
    "    pool.map(task, ids)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Create a consumer to consume and delete all the messages we put \n",
    "\n",
    "You can hold this step and inspect what the queue look like in Azure Storage Explore under your subscription -> queues -> queue.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The example code in azure storage official tutorial will delete all record.\n",
    "# One thing I realize is the queue doesn't really be in order.\n",
    "\n",
    "'''\n",
    "    bisibility_timeout is the \"lock\" of a record to make sure the \"uniqueness\"\n",
    "'''\n",
    "messages = queue_client.receive_messages(messages_per_page=5, visibility_timeout=5*60)\n",
    "\n",
    "for msg_batch in messages.by_page():\n",
    "    for msg in msg_batch:\n",
    "        print(\"Batch dequeue message: \" + msg.content)\n",
    "        queue_client.delete_message(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
